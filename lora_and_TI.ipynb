{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Upload images for training. The images should predominantly be close-ups. Include 2-3 full-body images for a broader perspective.\n",
        "\n"
      ],
      "metadata": {
        "id": "XC2mzqq-VW2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/"
      ],
      "metadata": {
        "id": "clQGUbwLPtHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now we install the lora github repo https://github.com/cloneofsimo/lora.git"
      ],
      "metadata": {
        "id": "J0kgAoJtVcRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/cloneofsimo/lora.git"
      ],
      "metadata": {
        "id": "pnPXlrn7O0M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We must resize the input images to a 512x512 resolution to facilitate expedited training. Assign the image location to the \"instance_data_dir\" parameter. The base model for training is determined by the \"pretrained_model_name_or_path\" parameter. The \"lora_rank\" parameter controls the image generation fidelity; a higher value results in higher fidelity but also extends training time. If the lora rank is increased, be sure to also increase the maximum training steps to prevent noisy generations.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZHoIcbVNY4lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lora_pti --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" --instance_data_dir=\"/content/input_images/\" --output_dir=\"/content/output/\" --train_text_encoder --resolution=512 \\\n",
        "--train_batch_size=1 --gradient_accumulation_steps=4 --scale_lr --learning_rate_unet=1e-4 --learning_rate_text=5e-5 --learning_rate_ti=5e-2 \\\n",
        "--color_jitter --lr_scheduler=\"linear\" --lr_warmup_steps=0 --placeholder_tokens=\"<s1>\" --initializer_tokens=\"man\" --use_template=\"object\" \\\n",
        "--save_steps=100 --max_train_steps_ti=1000 --max_train_steps_tuning=1000 --perform_inversion=True --clip_ti_decay --weight_decay_ti=0.000 \\\n",
        "--weight_decay_lora=0.001 --continue_inversion --continue_inversion_lr=1e-4 --device=\"cuda:0\" --lora_rank=8"
      ],
      "metadata": {
        "id": "SNMV0m1_MJZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#After training, convert the resulting safetensors model diffusers model using the lora_add command and combining the safetensors with the base stable diffusion model"
      ],
      "metadata": {
        "id": "fa5zHMQfWBIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lora_add runwayml/stable-diffusion-v1-5 /content/output/final_lora.safetensors /content/output_merged 0.8 --mode upl"
      ],
      "metadata": {
        "id": "8iHrPhSwtynp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.10.2 transformers scipy ftfy accelerate"
      ],
      "metadata": {
        "id": "5zB9h0x7vFrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wh-EdvySuqd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"/content/output_merged\")\n",
        "pipe.to(\"cuda\")\n",
        "prompt = \"a photograph of a man <s1> riding a horse\"\n",
        "\n",
        "image = pipe(prompt).images[0]"
      ],
      "metadata": {
        "id": "ha6blejwueHw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}